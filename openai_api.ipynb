{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "271d42b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e3d32f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (1.91.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml_dl_project\\tensor_proj\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae4f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "#print('key:', OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e2fef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client =  OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "507c0b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client =  OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input='ìŠ¤íƒ€ì›Œì¦ˆ ì‹œë¦¬ì¦ˆì˜ ë‹¤ìŠ¤ë² ì´ë”ì˜ ì—­í• ì— ëŒ€í•´ í•œì¤„ë¡œ ì„¤ë²™í•´ì¤˜'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "100a5e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë‹¤ìŠ¤ë² ì´ë”ëŠ” ìŠ¤íƒ€ì›Œì¦ˆ ì‹œë¦¬ì¦ˆì—ì„œ í¬ìŠ¤ë¥¼ ì–´ë‘ ì˜ í¸ì— ì‚¬ìš©í•˜ë©° ì€í•˜ ì œêµ­ì˜ ìƒì§•ì ì¸ ì•…ì—­ìœ¼ë¡œ ë“±ì¥í•˜ëŠ” ìºë¦­í„°ì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "092ff570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¤ìŠ¤ ë² ì´ë”ëŠ” ìŠ¤íƒ€ì›Œì¦ˆ ì‹œë¦¬ì¦ˆì—ì„œ ê³¼ê±°ì˜ ì˜ì›…ì´ì íƒ€ë½í•œ ì œë‹¤ì´ë¡œ, ì€í•˜ ì œêµ­ì˜ ìœ„í˜‘ê³¼ ì•„ë²„ì§€ë¡œì„œì˜ ë¹„ê·¹ì„ ìƒì§•í•˜ëŠ” ì•„ì´ì½˜ì´ë‹¤.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    instructions='ë‹¹ì‹ ì€ ì˜í™”í‰ë¡ ê°€ì•¼!',\n",
    "    input='ìŠ¤íƒ€ì›Œì¦ˆ ì‹œë¦¬ì¦ˆì˜ ë‹¤ìŠ¤ë² ì´ë”ì˜ ì—­í• ì— ëŒ€í•´ í•œì¤„ë¡œ ì„¤ëª…í•´ì¤˜'\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜¤ëŠ˜ì€ íŠ¹ë³„íˆ ì–´ë–¤ ìŒì‹ì´ ë•¡ê¸°ë‚˜ìš”? ì•„ë‹ˆë©´, ê°„ë‹¨í•˜ê²Œ ì¶”ì²œì„ í•´ì¤„ê¹Œìš”?\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´,\n",
      "\n",
      "- **í•œì‹**: ì§‘ë°¥ ëŠë‚Œ ë‚˜ëŠ” ê¹€ì¹˜ì°Œê°œ, ì œìœ¡ë³¶ìŒ, ë¹„ë¹”ë°¥\n",
      "- **ì¤‘ì‹**: ì§œì¥ë©´, íƒ•ìˆ˜ìœ¡, ë§ˆíŒŒë‘ë¶€\n",
      "- **ì¼ì‹**: ìŠ¤ì‹œ, ì¹´ë ˆ, ê·œë™\n",
      "- **ì–‘ì‹**: íŒŒìŠ¤íƒ€, ìŠ¤í…Œì´í¬, ìƒëŸ¬ë“œ, ì¹˜í‚¨\n",
      "- **ë¶„ì‹**: ë–¡ë³¶ì´, ìˆœëŒ€, ê¹€ë°¥, ë¼ë©´\n",
      "\n",
      "ì§‘ì— ìˆëŠ” ì¬ë£Œë¥¼ ì•Œë ¤ì£¼ì‹œë©´ í™œìš©í•  ë ˆì‹œí”¼ë„ ì¶”ì²œë“œë¦´ ìˆ˜ ìˆì–´ìš”!  \n",
      "í˜¹ì‹œ ê¸°ë¶„ì´ë‚˜ ìƒí™©(í˜¼ë°¥, ê°€ì¡±ê³¼, ì¹œêµ¬ì™€ ë“±)ì— ë§ì¶°ì„œë„ ì¶”ì²œí•´ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤ :)\n",
      "\n",
      "ì¡°ê¸ˆë§Œ ë” íŒíŠ¸ë¥¼ ì£¼ì‹œë©´ ë” ë”± ë§ëŠ” ë©”ë‰´ë¥¼ ì¶”ì²œí•´ ë“œë¦´ ìˆ˜ ìˆì–´ìš”!\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=[\n",
    "        {\n",
    "            'role': 'developer',\n",
    "            'content': 'ìŒì‹ì— ëŒ€í•œ ì´ì•¼ê¸° í•˜ëŠ”ê²ƒì„ ì¢‹ì•„í•´'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'ì˜¤ëŠ˜ì€ ë¬´ì—‡ì„ ë¨¹ì„ê¹Œ?'\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "432da534",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4.1',\n",
    "    messages= [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'ìŠ¤íƒ€ì›Œì¦ˆì‹œë¦¬ì¦ˆì— ëŒ€í•´ í•œë¶„ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜'\n",
    "        }\n",
    "    ]  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d2de517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ìŠ¤íƒ€ì›Œì¦ˆ ì‹œë¦¬ì¦ˆëŠ” ì€í•˜ê³„ì˜ ì„ ê³¼ ì•…ì˜ ëŒ€ê²°, ì œë‹¤ì´ì™€ ì‹œìŠ¤, ë‹¤ì–‘í•œ ìºë¦­í„°ì™€ ì¢…ì¡±ì´ ë“±ì¥í•˜ëŠ” ê´‘ëŒ€í•œ ì„¸ê³„ê´€ ì†ì—ì„œ ììœ ì™€ ì •ì˜, ê°€ì¡±ê³¼ ìš´ëª…ì„ ë‹¤ë£¨ëŠ” SF íŒíƒ€ì§€ ì˜í™” ì‹œë¦¬ì¦ˆì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dict(completion.choices[0])\n",
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f60b9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì§ˆë¬¸: \n",
      "ì•ˆë…•~! ìš°ë¦¬ ì¹œêµ¬ ë°˜ê°€ì›Œìš”ğŸ˜Š ì˜¤ëŠ˜ì€ ì–´ë–¤ ì¬ë¯¸ìˆëŠ” ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì¤„ê¹Œ? ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ë©´ ë­ë“ ì§€ ë¬¼ì–´ë´ë„ ë¼ìš”! ì„ ìƒë‹˜ì´ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì¤„ê²Œìš”. ìš°ë¦¬ ë‹¤ ê°™ì´ ì¦ê²ê²Œ ë†€ë©´ì„œ ë°°ì›Œë³¼ê¹Œìš”?ğŸ‘‹âœ¨\n"
     ]
    }
   ],
   "source": [
    "user_input = input('ì•ˆë…•í•˜ì„¸ìš”. ë¬´ì—‡ì´ êµ¼ê¸ˆí•˜ì‹ ê°€ìš”? ì§ˆë¬¸ì„ ë‚¨ê²¨ì£¼ì„¸ìš”!!!')\n",
    "print('ì§ˆë¬¸:', user_input)\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=[\n",
    "        {\n",
    "            'role': 'developer',\n",
    "            'content': 'ë„ˆëŠ” ìœ ì¹˜ì› ì„ ìƒë‹˜ì´ì•¼. ì•„ì´ë“¤ì„ ëŒ€í•˜ëŠ”ê²ƒì²˜ëŸ¼ ì´ì•¼ê¸°í•´ì¤˜'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': user_input\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a60bc3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36193db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_weather(latitude, longitude):\n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
    "    data = response.json()\n",
    "    return data['current']['temperature_2m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f77d2e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"latitude\": {\"type\": \"number\"},\n",
    "            \"longitude\": {\"type\": \"number\"}\n",
    "        },\n",
    "    \"required\": [\"latitude\", \"longitude\"],\n",
    "    \"additionalProperties\": False\n",
    "    },\n",
    "    \"strict\": True\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e07ed015",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_messages = [{ 'role': 'user', 'content':'ì˜¤ëŠ˜ íŒŒë¦¬ ë‚ ì”¨ ì–´ë•Œ?'}]\n",
    "\n",
    "# í•¨ìˆ˜ í˜¸ì¶œí•˜ëŠ” ê¸°ëŠ¥\n",
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=input_messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43d806cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arguments': '{\"latitude\":48.8566,\"longitude\":2.3522}',\n",
       " 'call_id': 'call_0OEmbaeoLDqcTXOiuHPDeGjS',\n",
       " 'name': 'get_weather',\n",
       " 'type': 'function_call',\n",
       " 'id': 'fc_685cd00d0f4081998d310291b6f4bd2c06ac7c96e5934b8a',\n",
       " 'status': 'completed'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(response.output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "725b06b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "tool_call = response.output[0]\n",
    "args = json.loads(tool_call.arguments)\n",
    "\n",
    "result = get_weather(args[\"latitude\"], args[\"longitude\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc89eafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜¤ëŠ˜ íŒŒë¦¬ì˜ í˜„ì¬ ê¸°ì˜¨ì€ ì•½ 20.5Â°Cì…ë‹ˆë‹¤. ì¾Œì í•œ ë‚ ì”¨ë„¤ìš”! ë‹¤ë¥¸ ì •ë³´ê°€ í•„ìš”í•˜ì‹ ê°€ìš”?\n"
     ]
    }
   ],
   "source": [
    "input_messages.append(tool_call)\n",
    "input_messages.append({\n",
    "    'type' : 'function_call_output',\n",
    "    'call_id': tool_call.call_id,\n",
    "    'output': str(result)\n",
    "})\n",
    "\n",
    "# ìµœì¢… ì‘ë‹µ\n",
    "response2 = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=input_messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "print(response2.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d36efb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.basic_tools import calculate_age, convert_currency, calculate_bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d295288",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"calculate_age\",\n",
    "        \"description\": \"ì…ë ¥ëœ ìƒë…„ì›”ì¼(YYYY-mm-dd)ë¡œ ë§Œ ë‚˜ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"birthdate\": {\"type\": \"string\", \"description\": \"ìƒë…„ì›”ì¼, í˜•ì‹:YYYY-MM-DD\"}\n",
    "            },\n",
    "        \"required\": [\"birthdate\"],\n",
    "        \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"convert_currency\",\n",
    "        \"description\": \"ì…ë ¥ëœ ë‹¬ëŸ¬(USD)ë¥¼ ì›í™”(KRW)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"amount\": {\"type\": \"number\", \"description\": \"ë‹¬ëŸ¬(USD) ê¸ˆì•¡\"}\n",
    "            },\n",
    "        \"required\": [\"amount\"],\n",
    "        \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"calculate_bmi\",\n",
    "        \"description\": \"í‚¤(cm), ëª¸ë¬´ê²Œ(kg) ì •ë³´ë¥¼ ë°›ì•„ì„œ BMIë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"height\": {\"type\": \"number\", \"description\": \"í‚¤(cm)\"},\n",
    "                \"weight\": {\"type\": \"number\", \"description\": \"ëª¸ë¬´ê²Œ(cm)\"}\n",
    "            },\n",
    "        \"required\": [\"height\", \"weight\"],\n",
    "        \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04c8e850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResponseFunctionToolCall(arguments='{\"birthdate\":\"1990-01-01\"}', call_id='call_4Kz3UbOCOzmJNFmyH4v3CiuF', name='calculate_age', type='function_call', id='fc_685cd01066a88198a8903887aed2241705ab1123ab438b36', status='completed'), ResponseFunctionToolCall(arguments='{\"amount\":100}', call_id='call_jCSn5QhgIzSr3uWxwsIPALAg', name='convert_currency', type='function_call', id='fc_685cd0107d3481988506d56f880eee4105ab1123ab438b36', status='completed'), ResponseFunctionToolCall(arguments='{\"height\":190,\"weight\":50}', call_id='call_suwPRZVGnmaooTmOtVRylaA6', name='calculate_bmi', type='function_call', id='fc_685cd010945c8198bcc7e2bd7b1ace0e05ab1123ab438b36', status='completed')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_messages = [\n",
    "    {\n",
    "        \"role\" : \"user\",\n",
    "        \"content\": \"ë‚´ ìƒì¼ì€ 1990-01-01 ì´ê³ , 100 ë‹¬ëŸ¬ë¥¼ ê°€ì§€ê³  ìˆëŠ”ë° ì›í™”ë¡œ ë³€í™˜í•´ì¤˜, ê·¸ë¦¬ê³  ë‚´ í‚¤ëŠ” 190cm ì´ê³  ëª¸ë¬´ê²ŒëŠ” 50kg ì´ì•¼ BMI ì ìˆ˜ë¥¼ ì•Œë ¤ì¤˜\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=input_messages,\n",
    "    tools=fn_tools\n",
    ")\n",
    "\n",
    "print(response.output)\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c395f79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseFunctionToolCall(arguments='{\"birthdate\":\"1990-01-01\"}', call_id='call_4Kz3UbOCOzmJNFmyH4v3CiuF', name='calculate_age', type='function_call', id='fc_685cd01066a88198a8903887aed2241705ab1123ab438b36', status='completed')\n",
      "ResponseFunctionToolCall(arguments='{\"amount\":100}', call_id='call_jCSn5QhgIzSr3uWxwsIPALAg', name='convert_currency', type='function_call', id='fc_685cd0107d3481988506d56f880eee4105ab1123ab438b36', status='completed')\n",
      "ResponseFunctionToolCall(arguments='{\"height\":190,\"weight\":50}', call_id='call_suwPRZVGnmaooTmOtVRylaA6', name='calculate_bmi', type='function_call', id='fc_685cd010945c8198bcc7e2bd7b1ace0e05ab1123ab438b36', status='completed')\n"
     ]
    }
   ],
   "source": [
    "print(response.output[0])\n",
    "print(response.output[1])\n",
    "print(response.output[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80de64f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜¸ì¶œ ë„êµ¬:calculate_age\n",
      "ë§¤ê°œë³€ìˆ˜: {\"birthdate\":\"1990-01-01\"}\n",
      "í˜¸ì¶œ ë„êµ¬:convert_currency\n",
      "ë§¤ê°œë³€ìˆ˜: {\"amount\":100}\n",
      "í˜¸ì¶œ ë„êµ¬:calculate_bmi\n",
      "ë§¤ê°œë³€ìˆ˜: {\"height\":190,\"weight\":50}\n",
      "[{'role': 'user', 'content': 'ë‚´ ìƒì¼ì€ 1990-01-01 ì´ê³ , 100 ë‹¬ëŸ¬ë¥¼ ê°€ì§€ê³  ìˆëŠ”ë° ì›í™”ë¡œ ë³€í™˜í•´ì¤˜, ê·¸ë¦¬ê³  ë‚´ í‚¤ëŠ” 190cm ì´ê³  ëª¸ë¬´ê²ŒëŠ” 50kg ì´ì•¼ BMI ì ìˆ˜ë¥¼ ì•Œë ¤ì¤˜'}, ResponseFunctionToolCall(arguments='{\"birthdate\":\"1990-01-01\"}', call_id='call_4Kz3UbOCOzmJNFmyH4v3CiuF', name='calculate_age', type='function_call', id='fc_685cd01066a88198a8903887aed2241705ab1123ab438b36', status='completed'), {'type': 'function_call_output', 'call_id': 'call_4Kz3UbOCOzmJNFmyH4v3CiuF', 'output': '35'}, ResponseFunctionToolCall(arguments='{\"amount\":100}', call_id='call_jCSn5QhgIzSr3uWxwsIPALAg', name='convert_currency', type='function_call', id='fc_685cd0107d3481988506d56f880eee4105ab1123ab438b36', status='completed'), {'type': 'function_call_output', 'call_id': 'call_jCSn5QhgIzSr3uWxwsIPALAg', 'output': '133000'}, ResponseFunctionToolCall(arguments='{\"height\":190,\"weight\":50}', call_id='call_suwPRZVGnmaooTmOtVRylaA6', name='calculate_bmi', type='function_call', id='fc_685cd010945c8198bcc7e2bd7b1ace0e05ab1123ab438b36', status='completed'), {'type': 'function_call_output', 'call_id': 'call_suwPRZVGnmaooTmOtVRylaA6', 'output': '13.85'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "if response.output :\n",
    "    for tool_call in response.output:\n",
    "        if tool_call.type == 'function_call':\n",
    "            if tool_call.name == 'calculate_age':\n",
    "                print(f'í˜¸ì¶œ ë„êµ¬:{tool_call.name}')\n",
    "                print(f'ë§¤ê°œë³€ìˆ˜: {tool_call.arguments}')\n",
    "                # ë§¤ê°œë³€ìˆ˜ ì¶”ì¶œ\n",
    "                args = json.loads(tool_call.arguments)\n",
    "                # í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼\n",
    "                result = calculate_age(args['birthdate'])\n",
    "                input_messages.append(tool_call)\n",
    "                input_messages.append({\n",
    "                    \"type\" : \"function_call_output\",\n",
    "                    \"call_id\": tool_call.call_id,\n",
    "                    \"output\": str(result)\n",
    "                })\n",
    "            \n",
    "            \n",
    "            if tool_call.name == 'convert_currency':\n",
    "                print(f'í˜¸ì¶œ ë„êµ¬:{tool_call.name}')\n",
    "                print(f'ë§¤ê°œë³€ìˆ˜: {tool_call.arguments}')\n",
    "\n",
    "                # ë§¤ê°œë³€ìˆ˜ ì¶”ì¶œ\n",
    "                args = json.loads(tool_call.arguments)\n",
    "\n",
    "                # í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼\n",
    "                result = convert_currency(args['amount'])\n",
    "\n",
    "                input_messages.append(tool_call)\n",
    "                input_messages.append({\n",
    "                    \"type\" : \"function_call_output\",\n",
    "                    \"call_id\": tool_call.call_id,\n",
    "                    \"output\": str(result)\n",
    "                })\n",
    "            \n",
    "            if tool_call.name == 'calculate_bmi':\n",
    "                print(f'í˜¸ì¶œ ë„êµ¬:{tool_call.name}')\n",
    "                print(f'ë§¤ê°œë³€ìˆ˜: {tool_call.arguments}')\n",
    "\n",
    "                # ë§¤ê°œë³€ìˆ˜ ì¶”ì¶œ\n",
    "                args = json.loads(tool_call.arguments)\n",
    "\n",
    "                # í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼\n",
    "                result = calculate_bmi(args['height'],args['weight'])\n",
    "\n",
    "                input_messages.append(tool_call)\n",
    "                input_messages.append({\n",
    "                    \"type\" : \"function_call_output\",\n",
    "                    \"call_id\": tool_call.call_id,\n",
    "                    \"output\": str(result)\n",
    "                })\n",
    "\n",
    "print(input_messages)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d1bf33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ë§Œ ë‚˜ì´ëŠ” 35ì„¸ì…ë‹ˆë‹¤.\n",
      "- 100ë‹¬ëŸ¬ëŠ” ì•½ 133,000ì›ì…ë‹ˆë‹¤.\n",
      "- í‚¤ 190cm, ëª¸ë¬´ê²Œ 50kg ê¸°ì¤€ BMIëŠ” 13.85ë¡œ, ì €ì²´ì¤‘ì— í•´ë‹¹í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "response_msg = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=input_messages,\n",
    "    tools=fn_tools\n",
    ")\n",
    "\n",
    "print(response_msg.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b9ac3c",
   "metadata": {},
   "source": [
    "### File Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4829e83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "#from openai import OpenAI\n",
    "\n",
    "#client = OpenAI()\n",
    "\n",
    "def create_file(client, file_path):\n",
    "    if file_path.startswith(\"http://\") or file_path.startswith(\"https://\"):\n",
    "        # Download the file content from the URL\n",
    "        response = requests.get(file_path)\n",
    "        file_content = BytesIO(response.content)\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        file_tuple = (file_name, file_content)\n",
    "        result = client.files.create(\n",
    "            file=file_tuple,\n",
    "            purpose=\"assistants\"\n",
    "        )\n",
    "    else:\n",
    "        # Handle local file path\n",
    "        with open(file_path, \"rb\") as file_content:\n",
    "            result = client.files.create(\n",
    "                file=file_content,\n",
    "                purpose=\"assistants\"\n",
    "            )\n",
    "    print(result.id)\n",
    "    return result.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f34382cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-1TYoyaaBCuda9UZk83cnS4\n"
     ]
    }
   ],
   "source": [
    "file_id = create_file(client, './howto-sockets.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc15ac83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_685cd181f51c8191a1917d95f8c9fd1a\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.vector_stores.create(\n",
    "    name='knowledge_base'\n",
    ")\n",
    "\n",
    "print(vector_store.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "807ce23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreFile(id='file-1TYoyaaBCuda9UZk83cnS4', created_at=1750913410, last_error=None, object='vector_store.file', status='in_progress', usage_bytes=0, vector_store_id='vs_685cd181f51c8191a1917d95f8c9fd1a', attributes={}, chunking_strategy=StaticFileChunkingStrategyObject(static=StaticFileChunkingStrategy(chunk_overlap_tokens=400, max_chunk_size_tokens=800), type='static'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store.id,\n",
    "    file_id=file_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30d4f550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[VectorStoreFile](data=[VectorStoreFile(id='file-1TYoyaaBCuda9UZk83cnS4', created_at=1750913410, last_error=None, object='vector_store.file', status='in_progress', usage_bytes=0, vector_store_id='vs_685cd181f51c8191a1917d95f8c9fd1a', attributes={}, chunking_strategy=StaticFileChunkingStrategyObject(static=StaticFileChunkingStrategy(chunk_overlap_tokens=400, max_chunk_size_tokens=800), type='static'))], has_more=False, object='list', first_id='file-1TYoyaaBCuda9UZk83cnS4', last_id='file-1TYoyaaBCuda9UZk83cnS4')\n"
     ]
    }
   ],
   "source": [
    "result_list = client.vector_stores.files.list(\n",
    "    vector_store_id=vector_store.id\n",
    ")\n",
    "\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "161bf4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_685cd1836d10819ab5cf1c3cd80e595301affa5d4c0dd025', created_at=1750913411.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseFileSearchToolCall(id='fs_685cd1841e1c819abef53887e158825901affa5d4c0dd025', queries=['íŒŒì´ì¬ ì†Œì¼“ ë§Œë“œëŠ” ë°©ë²•', 'íŒŒì´ì¬ ì†Œì¼“ ì½”ë“œ ì˜ˆì‹œ', 'íŒŒì´ì¬ ì†Œì¼“ ê°„ë‹¨ ì„¤ëª…', 'How to make a socket in Python'], status='completed', type='file_search_call', results=None), ResponseOutputMessage(id='msg_685cd186b040819a9e4b650c8326879101affa5d4c0dd025', content=[ResponseOutputText(annotations=[AnnotationFileCitation(file_id='file-1TYoyaaBCuda9UZk83cnS4', filename='howto-sockets.pdf', index=810, type='file_citation')], text='íŒŒì´ì¬ì—ì„œ ì†Œì¼“ì„ ë§Œë“œëŠ” ë°©ë²•ì„ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\n\\n### 1. ì†Œì¼“ ëª¨ë“ˆ ì„í¬íŠ¸\\n```python\\nimport socket\\n```\\n\\n### 2. ì†Œì¼“ ê°ì²´ ìƒì„±\\n```python\\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\n```\\n- `AF_INET`ì€ IPv4ë¥¼, `SOCK_STREAM`ì€ TCP í”„ë¡œí† ì½œì„ ì‚¬ìš©í•œë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤.\\n\\n### 3. ì„œë²„(ìˆ˜ì‹ ì)ì™€ í´ë¼ì´ì–¸íŠ¸(ì†¡ì‹ ì) êµ¬ë¶„\\n\\n#### (1) í´ë¼ì´ì–¸íŠ¸ ì†Œì¼“ (ì ‘ì†í•˜ëŠ” ìª½)\\n```python\\ns.connect((\"www.python.org\", 80))  # (\"í˜¸ìŠ¤íŠ¸\", í¬íŠ¸)\\n```\\n\\n#### (2) ì„œë²„ ì†Œì¼“ (ëŒ€ê¸°í•˜ëŠ” ìª½)\\n```python\\n# 1) ì£¼ì†Œì™€ í¬íŠ¸ í• ë‹¹(ë°”ì¸ë“œ)\\ns.bind((\"localhost\", 12345))  # (\"í˜¸ìŠ¤íŠ¸\", í¬íŠ¸)\\n# 2) ì—°ê²° ìš”ì²­ ëŒ€ê¸° ìƒíƒœë¡œ ì„¤ì •\\ns.listen(5)  # 5ëŠ” ì—°ê²° ëŒ€ê¸° íì˜ í¬ê¸°\\n\\nwhile True:\\n    clientsocket, address = s.accept()  # í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ê¸°ë‹¤ë¦¬ê¸°\\n    # ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ì™€ ë°ì´í„° ì£¼ê³ ë°›ê¸°\\n```\\n\\n### 4. ë°ì´í„° ì†¡ìˆ˜ì‹ \\n- ë°ì´í„° ë³´ë‚´ê¸°: `s.send(b\"ë©”ì‹œì§€\")`\\n- ë°ì´í„° ë°›ê¸°: `s.recv(1024)`  # 1024ë°”ì´íŠ¸ê¹Œì§€ ì½ê¸°\\n\\n### 5. ì†Œì¼“ ì¢…ë£Œ\\n```python\\ns.close()\\n```\\n\\n---\\n\\nì„œë²„ì™€ í´ë¼ì´ì–¸íŠ¸ëŠ” ìœ„ì™€ ê°™ì´ ì—­í• ì´ ë‹¤ë¥´ë©°, ë³´í†µ ì„œë²„ëŠ” `bind`â†’`listen`â†’`accept`, í´ë¼ì´ì–¸íŠ¸ëŠ” `connect` ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤.\\n\\n#### ì°¸ê³  ì½”ë“œ(ì„œë²„):\\n```python\\nimport socket\\n\\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\ns.bind((\"localhost\", 12345))\\ns.listen(1)\\nconn, addr = s.accept()\\ndata = conn.recv(1024)\\nconn.send(b\"Hello Client!\")\\nconn.close()\\ns.close()\\n```\\n\\n#### ì°¸ê³  ì½”ë“œ(í´ë¼ì´ì–¸íŠ¸):\\n```python\\nimport socket\\n\\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\ns.connect((\"localhost\", 12345))\\ns.send(b\"Hello Server!\")\\ndata = s.recv(1024)\\ns.close()\\n```\\n\\nê°„ëµí•˜ê²Œ ë§í•˜ë©´, `socket.socket()`ìœ¼ë¡œ ì†Œì¼“ì„ ë§Œë“¤ê³ , ì„œë²„ë¼ë©´ `bind`, `listen`, `accept`ë¥¼, í´ë¼ì´ì–¸íŠ¸ë¼ë©´ `connect`ë¥¼ ì°¨ë¡€ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì†¡ìˆ˜ì‹ ì´ ëë‚˜ë©´ `close()`ë¡œ ì†Œì¼“ì„ ë‹«ìœ¼ë©´ ë©ë‹ˆë‹¤.', type='output_text', logprobs=None)], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='required', tools=[FileSearchTool(type='file_search', vector_store_ids=['vs_685cd181f51c8191a1917d95f8c9fd1a'], filters=None, max_num_results=20, ranking_options=RankingOptions(ranker='auto', score_threshold=0.0))], top_p=1.0, background=False, max_output_tokens=None, previous_response_id=None, prompt=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=8594, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=649, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=9243), user=None, max_tool_calls=None, store=True)\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input='íŒŒì´ì¬ ì½”ë“œë¡œ ì†Œì¼“ ë§Œë“œëŠ” ë°©ë²•ì„ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ì¤˜',\n",
    "    tools=[{\n",
    "        \"type\" : \"file_search\",\n",
    "        \"vector_store_ids\" : [vector_store.id]\n",
    "    }],\n",
    "    tool_choice='required'\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2d69482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'resp_685cd1836d10819ab5cf1c3cd80e595301affa5d4c0dd025', 'created_at': 1750913411.0, 'error': None, 'incomplete_details': None, 'instructions': None, 'metadata': {}, 'model': 'gpt-4.1-2025-04-14', 'object': 'response', 'output': [ResponseFileSearchToolCall(id='fs_685cd1841e1c819abef53887e158825901affa5d4c0dd025', queries=['íŒŒì´ì¬ ì†Œì¼“ ë§Œë“œëŠ” ë°©ë²•', 'íŒŒì´ì¬ ì†Œì¼“ ì½”ë“œ ì˜ˆì‹œ', 'íŒŒì´ì¬ ì†Œì¼“ ê°„ë‹¨ ì„¤ëª…', 'How to make a socket in Python'], status='completed', type='file_search_call', results=None), ResponseOutputMessage(id='msg_685cd186b040819a9e4b650c8326879101affa5d4c0dd025', content=[ResponseOutputText(annotations=[AnnotationFileCitation(file_id='file-1TYoyaaBCuda9UZk83cnS4', filename='howto-sockets.pdf', index=810, type='file_citation')], text='íŒŒì´ì¬ì—ì„œ ì†Œì¼“ì„ ë§Œë“œëŠ” ë°©ë²•ì„ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\n\\n### 1. ì†Œì¼“ ëª¨ë“ˆ ì„í¬íŠ¸\\n```python\\nimport socket\\n```\\n\\n### 2. ì†Œì¼“ ê°ì²´ ìƒì„±\\n```python\\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\n```\\n- `AF_INET`ì€ IPv4ë¥¼, `SOCK_STREAM`ì€ TCP í”„ë¡œí† ì½œì„ ì‚¬ìš©í•œë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤.\\n\\n### 3. ì„œë²„(ìˆ˜ì‹ ì)ì™€ í´ë¼ì´ì–¸íŠ¸(ì†¡ì‹ ì) êµ¬ë¶„\\n\\n#### (1) í´ë¼ì´ì–¸íŠ¸ ì†Œì¼“ (ì ‘ì†í•˜ëŠ” ìª½)\\n```python\\ns.connect((\"www.python.org\", 80))  # (\"í˜¸ìŠ¤íŠ¸\", í¬íŠ¸)\\n```\\n\\n#### (2) ì„œë²„ ì†Œì¼“ (ëŒ€ê¸°í•˜ëŠ” ìª½)\\n```python\\n# 1) ì£¼ì†Œì™€ í¬íŠ¸ í• ë‹¹(ë°”ì¸ë“œ)\\ns.bind((\"localhost\", 12345))  # (\"í˜¸ìŠ¤íŠ¸\", í¬íŠ¸)\\n# 2) ì—°ê²° ìš”ì²­ ëŒ€ê¸° ìƒíƒœë¡œ ì„¤ì •\\ns.listen(5)  # 5ëŠ” ì—°ê²° ëŒ€ê¸° íì˜ í¬ê¸°\\n\\nwhile True:\\n    clientsocket, address = s.accept()  # í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ê¸°ë‹¤ë¦¬ê¸°\\n    # ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ì™€ ë°ì´í„° ì£¼ê³ ë°›ê¸°\\n```\\n\\n### 4. ë°ì´í„° ì†¡ìˆ˜ì‹ \\n- ë°ì´í„° ë³´ë‚´ê¸°: `s.send(b\"ë©”ì‹œì§€\")`\\n- ë°ì´í„° ë°›ê¸°: `s.recv(1024)`  # 1024ë°”ì´íŠ¸ê¹Œì§€ ì½ê¸°\\n\\n### 5. ì†Œì¼“ ì¢…ë£Œ\\n```python\\ns.close()\\n```\\n\\n---\\n\\nì„œë²„ì™€ í´ë¼ì´ì–¸íŠ¸ëŠ” ìœ„ì™€ ê°™ì´ ì—­í• ì´ ë‹¤ë¥´ë©°, ë³´í†µ ì„œë²„ëŠ” `bind`â†’`listen`â†’`accept`, í´ë¼ì´ì–¸íŠ¸ëŠ” `connect` ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤.\\n\\n#### ì°¸ê³  ì½”ë“œ(ì„œë²„):\\n```python\\nimport socket\\n\\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\ns.bind((\"localhost\", 12345))\\ns.listen(1)\\nconn, addr = s.accept()\\ndata = conn.recv(1024)\\nconn.send(b\"Hello Client!\")\\nconn.close()\\ns.close()\\n```\\n\\n#### ì°¸ê³  ì½”ë“œ(í´ë¼ì´ì–¸íŠ¸):\\n```python\\nimport socket\\n\\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\ns.connect((\"localhost\", 12345))\\ns.send(b\"Hello Server!\")\\ndata = s.recv(1024)\\ns.close()\\n```\\n\\nê°„ëµí•˜ê²Œ ë§í•˜ë©´, `socket.socket()`ìœ¼ë¡œ ì†Œì¼“ì„ ë§Œë“¤ê³ , ì„œë²„ë¼ë©´ `bind`, `listen`, `accept`ë¥¼, í´ë¼ì´ì–¸íŠ¸ë¼ë©´ `connect`ë¥¼ ì°¨ë¡€ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì†¡ìˆ˜ì‹ ì´ ëë‚˜ë©´ `close()`ë¡œ ì†Œì¼“ì„ ë‹«ìœ¼ë©´ ë©ë‹ˆë‹¤.', type='output_text', logprobs=None)], role='assistant', status='completed', type='message')], 'parallel_tool_calls': True, 'temperature': 1.0, 'tool_choice': 'required', 'tools': [FileSearchTool(type='file_search', vector_store_ids=['vs_685cd181f51c8191a1917d95f8c9fd1a'], filters=None, max_num_results=20, ranking_options=RankingOptions(ranker='auto', score_threshold=0.0))], 'top_p': 1.0, 'background': False, 'max_output_tokens': None, 'previous_response_id': None, 'prompt': None, 'reasoning': Reasoning(effort=None, generate_summary=None, summary=None), 'service_tier': 'default', 'status': 'completed', 'text': ResponseTextConfig(format=ResponseFormatText(type='text')), 'truncation': 'disabled', 'usage': ResponseUsage(input_tokens=8594, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=649, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=9243), 'user': None, 'max_tool_calls': None, 'store': True}\n"
     ]
    }
   ],
   "source": [
    "print(dict(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f2f00d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='ìŠ¤íƒ€ì›Œì¦ˆ ì‹œë¦¬ì¦ˆëŠ” ë¯¸ë˜ ì€í•˜ê³„ë¥¼ ë°°ê²½ìœ¼ë¡œ ì„ ê³¼ ì•…ì˜ ëŒ€ë¦½, ê°€ì¡±ì˜ ë¹„ê·¹ê³¼ ì˜ì›…ì˜ ì—¬ì •ì„ ê·¸ë¦° SF ì˜í™” í”„ëœì°¨ì´ì¦ˆì…ë‹ˆë‹¤.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4.1',\n",
    "    messages=[{\n",
    "        \"role\" : \"user\",\n",
    "        \"content\" : ' ìŠ¤íƒ€ì›Œì¦ˆ ì‹œë¦¬ì¦ˆì— ëŒ€í•´ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜'\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(completion.choices[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
