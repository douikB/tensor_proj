{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c01c50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.4-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.0-cp39-cp39-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.4-cp39-cp39-win_amd64.whl.metadata (108 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp39-cp39-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml,dl_project\\tensor_proj\\.venv\\lib\\site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml,dl_project\\tensor_proj\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.2.1-cp39-cp39-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml,dl_project\\tensor_proj\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml,dl_project\\tensor_proj\\.venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\0_codefile\\pythonproject\\sk_rookies26\\02_ml,dl_project\\tensor_proj\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.9.4-cp39-cp39-win_amd64.whl (7.8 MB)\n",
      "   ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 7.8/7.8 MB 40.2 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.0-cp39-cp39-win_amd64.whl (211 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.4-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 40.4 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading kiwisolver-1.4.7-cp39-cp39-win_amd64.whl (55 kB)\n",
      "Downloading pillow-11.2.1-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 38.3 MB/s eta 0:00:00\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "\n",
      "   ---------------------------------------- 0/8 [pyparsing]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ---------- ----------------------------- 2/8 [kiwisolver]\n",
      "   --------------- ------------------------ 3/8 [importlib-resources]\n",
      "   --------------- ------------------------ 3/8 [importlib-resources]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   -------------------- ------------------- 4/8 [fonttools]\n",
      "   ------------------------- -------------- 5/8 [cycler]\n",
      "   ------------------------------ --------- 6/8 [contourpy]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [matplotlib]\n",
      "   ---------------------------------------- 8/8 [matplotlib]\n",
      "\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.58.4 importlib-resources-6.5.2 kiwisolver-1.4.7 matplotlib-3.9.4 pillow-11.2.1 pyparsing-3.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f62aa8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 9. 학습 결과 시각화 (Optional)\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential # 순차적 모델을 생성하기 위한 모듈\n",
    "from tensorflow.keras.layers import Dense # 밀집층(fully connected layer)을 추가하기 위한 모듈\n",
    "from sklearn.model_selection import train_test_split# 데이터를 학습/테스트 세트로 나누기 위한 모듈\n",
    "from sklearn.datasets import make_classification # 예제 데이터셋 생성 모듈\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e31d11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=1000, # 데이터 샘플 수\n",
    "    n_features=20, # 특징(특성) 수\n",
    "    n_classes=2, # 클래스 수 (이진 분류)\n",
    "    random_state=42  # 랜덤 시드 고정 (결과 재현 가능성 보장)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e8ada07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e49d2eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\0_CodeFile\\PythonProject\\SK_rookies26\\02_ml,dl_project\\tensor_proj\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train.shape[1],)), # 첫 번째 은닉층\n",
    "    Dense(8, activation='relu'), # 두 번째 은닉층\n",
    "    Dense(1, activation='sigmoid') # 출력층 (이진 분류에서 사용)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c74d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam', # 학습 속도를 조정하며 손실 함수의 최솟값을 찾습니다.\n",
    "    loss='binary_crossentropy', # 이진 분류에서 자주 사용되는 손실 함수\n",
    "    metrics=['accuracy'] # 학습 성과를 평가할 지표\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b3d2c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4979 - loss: 0.7547 - val_accuracy: 0.5125 - val_loss: 0.6900\n",
      "Epoch 2/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5025 - loss: 0.6857 - val_accuracy: 0.5188 - val_loss: 0.6425\n",
      "Epoch 3/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5122 - loss: 0.6578 - val_accuracy: 0.5562 - val_loss: 0.6061\n",
      "Epoch 4/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5661 - loss: 0.6056 - val_accuracy: 0.6250 - val_loss: 0.5709\n",
      "Epoch 5/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5978 - loss: 0.5846 - val_accuracy: 0.6938 - val_loss: 0.5359\n",
      "Epoch 6/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6838 - loss: 0.5443 - val_accuracy: 0.7437 - val_loss: 0.5024\n",
      "Epoch 7/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7676 - loss: 0.5099 - val_accuracy: 0.7812 - val_loss: 0.4679\n",
      "Epoch 8/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7790 - loss: 0.4823 - val_accuracy: 0.8313 - val_loss: 0.4359\n",
      "Epoch 9/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8218 - loss: 0.4536 - val_accuracy: 0.8438 - val_loss: 0.4045\n",
      "Epoch 10/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8421 - loss: 0.4430 - val_accuracy: 0.8562 - val_loss: 0.3730\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train, # 학습용 데이터와 레이블\n",
    "    validation_split=0.2, # 검증 데이터 비율 (학습 데이터의 20%)\n",
    "    epochs=10, # 학습 반복 횟수\n",
    "    batch_size=32, # 한 번의 학습에서 사용하는 데이터 샘플 수\n",
    "    verbose=1           # 학습 진행 상태를 출력\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a605fdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7938 - loss: 0.4712 \n",
      "테스트 손실: 0.4759, 테스트 정확도: 0.8000\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"테스트 손실: {test_loss:.4f}, 테스트 정확도: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64ecefba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "예측 결과: [[0.7236289 ]\n",
      " [0.6168604 ]\n",
      " [0.36716196]\n",
      " [0.55826205]\n",
      " [0.6300857 ]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:5]) # 테스트 데이터 중 5개의 샘플 예측\n",
    "print(\"예측 결과:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de21ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 생성\n",
    "# 이진 분류를 위한 가상 데이터셋 생성\n",
    "X, y=make_classification(n_samples=1000, n_features=20,    \n",
    "n_informative=15, n_redundant=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7939609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 데이터 분할\n",
    "# (1) 전체 데이터를 훈련 데이터와 임시 데이터로 나눔 (훈련 70%, 나머지 30%)\n",
    "X_train, X_temp, y_train, y_temp=train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75e34574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 크기: (700, 20) (700,)\n",
      "검증 데이터 크기: (150, 20) (150,)\n",
      "테스트 데이터 크기: (150, 20) (150,)\n"
     ]
    }
   ],
   "source": [
    "# (2) 나머지 데이터를 검증 데이터와 테스트 데이터로 나눔 (각각 15%씩)\n",
    "X_val, X_test, y_val, y_test=train_test_split( X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "# 3. 각 데이터셋 크기 확인\n",
    "print(\"훈련 데이터 크기:\", X_train.shape, y_train.shape) # 약 70%의 데이터\n",
    "print(\"검증 데이터 크기:\", X_val.shape, y_val.shape) # 약 15%의 데이터\n",
    "print(\"테스트 데이터 크기:\", X_test.shape, y_test.shape) # 약 15%의 데이터\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "564b8534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화 (특성 스케일링)\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_val=scaler.transform(X_val)\n",
    "X_test=scaler.transform(X_test)\n",
    "# 2. 모델 설계\n",
    "# 입력층, 은닉층, 출력층으로 구성된 이진 분류 모델\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)), # 입력층\n",
    "    tf.keras.layers.Dense(64, activation='relu'), # 첫 번째 은닉층\n",
    "    tf.keras.layers.Dropout(0.5), # 과적합 방지를 위한 Dropout\n",
    "    tf.keras.layers.Dense(32, activation='relu'), # 두 번째 은닉층\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid') # 출력층 (Sigmoid 활성화 함수)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94ac9ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수: Binary Cross-Entropy\n",
    "# 최적화 알고리즘: Adam\n",
    "# 평가지표: Accuracy\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b89aa9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Early Stopping 설정\n",
    "# 검증 데이터 손실이 개선되지 않으면 학습을 조기에 종료\n",
    "early_stopping=tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20dad434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4932 - loss: 0.7622 - val_accuracy: 0.6867 - val_loss: 0.6159\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6822 - loss: 0.6251 - val_accuracy: 0.8333 - val_loss: 0.5311\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7572 - loss: 0.5372 - val_accuracy: 0.8533 - val_loss: 0.4579\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7850 - loss: 0.4973 - val_accuracy: 0.8533 - val_loss: 0.3977\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8297 - loss: 0.4385 - val_accuracy: 0.8800 - val_loss: 0.3429\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8253 - loss: 0.3932 - val_accuracy: 0.8733 - val_loss: 0.3081\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3794 - val_accuracy: 0.8800 - val_loss: 0.2770\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8618 - loss: 0.3635 - val_accuracy: 0.8800 - val_loss: 0.2645\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8450 - loss: 0.3555 - val_accuracy: 0.8933 - val_loss: 0.2478\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8720 - loss: 0.3247 - val_accuracy: 0.9000 - val_loss: 0.2325\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8963 - loss: 0.2747 - val_accuracy: 0.8933 - val_loss: 0.2218\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8947 - loss: 0.2664 - val_accuracy: 0.8933 - val_loss: 0.2143\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9225 - loss: 0.2269 - val_accuracy: 0.9000 - val_loss: 0.1989\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.2591 - val_accuracy: 0.9067 - val_loss: 0.1999\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8984 - loss: 0.2470 - val_accuracy: 0.9067 - val_loss: 0.1927\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9144 - loss: 0.2286 - val_accuracy: 0.9067 - val_loss: 0.1861\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2041 - val_accuracy: 0.9133 - val_loss: 0.1784\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9080 - loss: 0.2314 - val_accuracy: 0.9133 - val_loss: 0.1748\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8906 - loss: 0.2628 - val_accuracy: 0.9067 - val_loss: 0.1813\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8973 - loss: 0.2510 - val_accuracy: 0.9067 - val_loss: 0.1814\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9418 - loss: 0.1944 - val_accuracy: 0.9267 - val_loss: 0.1718\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9277 - loss: 0.2240 - val_accuracy: 0.9267 - val_loss: 0.1607\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9268 - loss: 0.2118 - val_accuracy: 0.9267 - val_loss: 0.1618\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9244 - loss: 0.1790 - val_accuracy: 0.9267 - val_loss: 0.1646\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9423 - loss: 0.1805 - val_accuracy: 0.9267 - val_loss: 0.1569\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9451 - loss: 0.1708 - val_accuracy: 0.9267 - val_loss: 0.1611\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9211 - loss: 0.1776 - val_accuracy: 0.9333 - val_loss: 0.1497\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1598 - val_accuracy: 0.9333 - val_loss: 0.1445\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.2123 - val_accuracy: 0.9333 - val_loss: 0.1432\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9294 - loss: 0.1695 - val_accuracy: 0.9267 - val_loss: 0.1400\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9298 - loss: 0.1660 - val_accuracy: 0.9333 - val_loss: 0.1418\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9409 - loss: 0.1632 - val_accuracy: 0.9333 - val_loss: 0.1384\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.1916 - val_accuracy: 0.9267 - val_loss: 0.1389\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9311 - loss: 0.1707 - val_accuracy: 0.9267 - val_loss: 0.1402\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9411 - loss: 0.1543 - val_accuracy: 0.9267 - val_loss: 0.1383\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9444 - loss: 0.1566 - val_accuracy: 0.9333 - val_loss: 0.1326\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9366 - loss: 0.1668 - val_accuracy: 0.9333 - val_loss: 0.1288\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9327 - loss: 0.1788 - val_accuracy: 0.9400 - val_loss: 0.1283\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9384 - loss: 0.1651 - val_accuracy: 0.9267 - val_loss: 0.1309\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9529 - loss: 0.1435 - val_accuracy: 0.9400 - val_loss: 0.1277\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9347 - loss: 0.1837 - val_accuracy: 0.9400 - val_loss: 0.1306\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9425 - loss: 0.1466 - val_accuracy: 0.9333 - val_loss: 0.1315\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9462 - loss: 0.1471 - val_accuracy: 0.9400 - val_loss: 0.1226\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1212 - val_accuracy: 0.9333 - val_loss: 0.1286\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1207 - val_accuracy: 0.9400 - val_loss: 0.1206\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1317 - val_accuracy: 0.9400 - val_loss: 0.1211\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 0.1477 - val_accuracy: 0.9400 - val_loss: 0.1168\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.1631 - val_accuracy: 0.9400 - val_loss: 0.1174\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9496 - loss: 0.1407 - val_accuracy: 0.9333 - val_loss: 0.1258\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1137 - val_accuracy: 0.9400 - val_loss: 0.1140\n"
     ]
    }
   ],
   "source": [
    " # 5. 모델 훈련\n",
    "history=model.fit(X_train, y_train, \n",
    "    validation_data=(X_val, y_val), \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da3c070f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9476 - loss: 0.1754 \n",
      "TestLoss: 0.1458, Test Accuracy: 0.9533\n"
     ]
    }
   ],
   "source": [
    "# 6. 모델 평가\n",
    "# 테스트 데이터로 성능 평가\n",
    "test_loss, test_accuracy=model.evaluate(X_test, y_test)\n",
    "print(f\"TestLoss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80986f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n"
     ]
    }
   ],
   "source": [
    "# 7. 예측\n",
    "# 새로운 데이터에 대한 예측 수행\n",
    "predictions=model.predict(X_test)\n",
    "predicted_classes=(predictions>0.5).astype(int) # 0.5를 기준으로 클래스 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b7ffdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ClassificationReport:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        79\n",
      "           1       0.93      0.97      0.95        71\n",
      "\n",
      "    accuracy                           0.95       150\n",
      "   macro avg       0.95      0.95      0.95       150\n",
      "weighted avg       0.95      0.95      0.95       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8. 분류 보고서 출력\n",
    "# 실제 값과 예측 값을 비교하여 성능 지표 확인\n",
    "print(\"\\nClassificationReport:\")\n",
    "print(classification_report(y_test, predicted_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673d0334",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 9. 학습 결과 시각화 (Optional)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 훈련 및 검증 손실 시각화\u001b[39;00m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 훈련 및 검증 손실 시각화\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# 훈련 및 검증 정확도 시각화\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56898b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
